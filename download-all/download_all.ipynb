{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import json\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sys\n",
    "import fac as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config for the FAC API.\n",
    "# You need a file in this directory called 'config.json'\n",
    "# It needs to look like this:\n",
    "# {\n",
    "#    \"FAC_API_KEY\": \"YOUR-KEY-HERE\",\n",
    "#    \"DATA_DIR\": \"data\"\n",
    "# }\n",
    "config = json.load(open(\"config.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = f.FAC()\n",
    "client.api_key(config[\"FAC_API_KEY\"])\n",
    "endpoints = [\"additional_ueis\", \"additional_eins\", \"general\", \"findings\", \"federal_awards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datapath(filename):\n",
    "    return os.path.join(config[\"DATA_DIR\"], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes around 93m to run, first time.\n",
    "for ep in endpoints:\n",
    "    ep_json_filepath = build_datapath(f\"{ep}.json\")\n",
    "    # If there is no JSON file for this table, go ahead and do the download.\n",
    "    if not os.path.isfile(ep_json_filepath):\n",
    "        client.endpoint(ep)\n",
    "        client.fetch()\n",
    "        with open(ep_json_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(client.results(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Write the metadata\n",
    "metadata_filepath = build_datapath(\"metadata.json\")\n",
    "if not os.path.isfile(metadata_filepath):\n",
    "    with open(metadata_filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(client.metadata(), f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS additional_ueis (report_id TEXT,auditee_uei TEXT,audit_year TEXT,additional_uei TEXT)\n",
      "CREATE TABLE IF NOT EXISTS additional_eins (report_id TEXT,auditee_uei TEXT,audit_year TEXT,additional_ein TEXT)\n",
      "CREATE TABLE IF NOT EXISTS general (report_id TEXT,auditee_uei TEXT,audit_year TEXT,auditee_certify_name TEXT,auditee_certify_title TEXT,auditee_contact_name TEXT,auditee_email TEXT,auditee_name TEXT,auditee_phone TEXT,auditee_contact_title TEXT,auditee_address_line_1 TEXT,auditee_city TEXT,auditee_state TEXT,auditee_ein TEXT,auditee_zip TEXT,auditor_certify_name TEXT,auditor_certify_title TEXT,auditor_phone TEXT,auditor_state TEXT,auditor_city TEXT,auditor_contact_title TEXT,auditor_address_line_1 TEXT,auditor_zip TEXT,auditor_country TEXT,auditor_contact_name TEXT,auditor_email TEXT,auditor_firm_name TEXT,auditor_foreign_address TEXT,auditor_ein TEXT,cognizant_agency TEXT,oversight_agency TEXT,date_created TEXT,ready_for_certification_date TEXT,auditor_certified_date TEXT,auditee_certified_date TEXT,submitted_date TEXT,fac_accepted_date TEXT,fy_end_date TEXT,fy_start_date TEXT,audit_type TEXT,gaap_results TEXT,sp_framework_basis TEXT,is_sp_framework_required TEXT,sp_framework_opinions TEXT,is_going_concern_included TEXT,is_internal_control_deficiency_disclosed TEXT,is_internal_control_material_weakness_disclosed TEXT,is_material_noncompliance_disclosed TEXT,dollar_threshold TEXT,is_low_risk_auditee TEXT,agencies_with_prior_findings TEXT,entity_type TEXT,number_months TEXT,audit_period_covered TEXT,total_amount_expended TEXT,type_audit_code TEXT,is_public TEXT,data_source TEXT,is_aicpa_audit_guide_included TEXT,is_additional_ueis TEXT,is_multiple_eins TEXT,is_secondary_auditors TEXT)\n",
      "CREATE TABLE IF NOT EXISTS findings (report_id TEXT,auditee_uei TEXT,audit_year TEXT,award_reference TEXT,reference_number TEXT,is_material_weakness TEXT,is_modified_opinion TEXT,is_other_findings TEXT,is_other_matters TEXT,prior_finding_ref_numbers TEXT,is_questioned_costs TEXT,is_repeat_finding TEXT,is_significant_deficiency TEXT,type_requirement TEXT)\n",
      "CREATE TABLE IF NOT EXISTS federal_awards (report_id TEXT,auditee_uei TEXT,audit_year TEXT,award_reference TEXT,federal_agency_prefix TEXT,federal_award_extension TEXT,additional_award_identification TEXT,federal_program_name TEXT,amount_expended TEXT,cluster_name TEXT,other_cluster_name TEXT,state_cluster_name TEXT,cluster_total TEXT,federal_program_total TEXT,is_major TEXT,is_loan TEXT,loan_balance TEXT,is_direct TEXT,audit_report_type TEXT,findings_count TEXT,is_passthrough_award TEXT,passthrough_amount TEXT)\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(build_datapath(\"fac.sqlite\"))\n",
    "\n",
    "# Create tables\n",
    "\n",
    "for ep in endpoints:\n",
    "    ep_json_filepath = build_datapath(f\"{ep}.json\")\n",
    "    with open(ep_json_filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        # Use the first object to create the table\n",
    "        fields = data[0].keys()\n",
    "        fields_with_commas = \",\".join(map(lambda f: f\"{f} TEXT\", fields))\n",
    "        stmt = f\"CREATE TABLE IF NOT EXISTS {ep} ({fields_with_commas})\"\n",
    "        print(stmt)\n",
    "        conn.execute(stmt)\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/additional_ueis.json\n",
      "Converting to dataframe: 12525 records\n",
      "Inserting\n",
      "Loading ../data/additional_eins.json\n",
      "Converting to dataframe: 55647 records\n",
      "Inserting\n",
      "Loading ../data/general.json\n",
      "Converting to dataframe: 312488 records\n",
      "Inserting\n",
      "Loading ../data/findings.json\n",
      "Converting to dataframe: 410808 records\n",
      "Inserting\n",
      "Loading ../data/federal_awards.json\n",
      "Converting to dataframe: 5175364 records\n",
      "Inserting\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "for ep in endpoints:\n",
    "    fname = ep_json_filepath = build_datapath(f\"{ep}.json\")\n",
    "    with open(fname, 'r') as f:\n",
    "        print(f\"Loading {fname}\")\n",
    "        jsn = json.load(f)\n",
    "        print(f\"Converting to dataframe: {len(jsn)} records\")\n",
    "        df = pd.DataFrame.from_records(jsn)\n",
    "        print(f\"Inserting\")\n",
    "        df.to_sql(ep, \n",
    "                  con=conn, \n",
    "                  if_exists='append', \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_time': 3.671,\n",
       " 'average_query_time': 0.918,\n",
       " 'query_count': 4,\n",
       " 'total_time_hms': '0:00:03'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Close the connection\n",
    "conn.close()\n",
    "client.metadata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
